function [Q, A, Snew] = actionAgent(S, M, Anet, ROADS, BETA)
%ACTIONAGENT Selcts an action for the agent
%
%   Parameters
%   ==========
%   S            - vector (agent's state, one-hot)
%   M            - vector (agent's motivation towards each city)
%   ANET         - DLNetwork (deep Q-model)
%   ROADS        - matrix (cities' adjacency matrix)
%   BETA         - double (inverse temperature for softmax decision)
%   Q            - vector (action values)
%   A            - number (next action generated by the model)
%   Snew         - vector (agent's updated state, one-hot)
%
%   Author
%   ======
%   Ngoc Tran,      2018-2019. ntran@cshl.edu
%   Sergey Shuvaev, 2019-2021. sshuvaev@cshl.edu

%Computing the Q-values
len = length(Anet);
Anet(1).setInput([S, M]);
for j = 2 : len - 1
    stepForward(Anet, j);
end
Q = Anet(len - 1).y .* ROADS(:, find(S));

%Softmax choice of an available action
A = randsample(length(Q), 1, true, exp(BETA .* Q) .* ROADS(:, find(S)));
Snew = zeros(size(S));
Snew(A) = 1;
